{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xtchen64/virtual-doctor-chatbot/blob/main/notebooks/llm_api_call.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Call ChatGPT API\n",
        "\n",
        "Written By: Qingyang Xu, Elaine Chen  \n",
        "Date Created: 11/24/2023  \n",
        "Last Modified: 11/24/2023  \n",
        "\n",
        "### Overview\n",
        "\n",
        "- Section 1. Call ChatGPT API\n",
        "\n",
        "\n",
        "### Section 1. Call ChatGPT API"
      ],
      "metadata": {
        "id": "dwEA07Dko68y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mAU7fwMEF-sI",
        "outputId": "385feee4-a449-4a05-e83a-3dd3cfb23cc9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.3.5-py3-none-any.whl (220 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/220.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m194.6/220.8 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.8/220.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<4,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.25.2-py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai) (4.5.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (1.1.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h11, httpcore, httpx, openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h11-0.14.0 httpcore-1.0.2 httpx-0.25.2 openai-1.3.5\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "from openai import OpenAI"
      ],
      "metadata": {
        "id": "zx1JKNBGW2mS"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_prompt(text: str, prompt_id=1):\n",
        "  \"\"\"\n",
        "  Define prompts here.\n",
        "  \"\"\"\n",
        "  # Prompt 1: Determine if answer contains symptoms:\n",
        "  # - if yes, process potential symptoms into a list\n",
        "  # - if not, ask user to provide symptoms\n",
        "  prompt1 = f\"\"\" Imagine you are a professional medical doctor and speaking with a patient. \\\n",
        "  The conversation with the patient is in the text below, delimited by triple backticks. \\\n",
        "  ```{text}```\n",
        "\n",
        "  Do one of the following, whichever is better:\n",
        "  1) If the patient provided any symptoms in the text, summarize the the symptoms in a Python list, for example: ['headache','toothache']. Do not say anything else besides this list.\n",
        "  2) If the patient did not provide any symptoms in the text, then do not respond with a list. Instead, respond to their message in conversation-style sentences, and then tell the patient politely that you did not hear any symptoms and ask the patient to provide their symptoms. Do not respond with a list in this scenario.\n",
        "  \"\"\"\n",
        "\n",
        "  # Prompt 2: Determine if the patient says the symptom list looks good:\n",
        "  # - if yes, answer one word (\"proceed\") only\n",
        "  # - if no,\n",
        "  #     1) if the patient wants to add any symptom, then append the symptom to the original symptom list, and return the symptom list, for example: ['headache','toothache','chest pain'].\n",
        "  #     2) if the patient wants to revise any existing symptom in the list, then revise the list by changing the relevant symptom(s), and return the symptom list, for example, ['headache','severe toothache']\n",
        "  #     3) if the patient wants to both 1 and 2, do it accordingly and return the symptom list\n",
        "  #     4) if the patient only says they want to add/revise the symptoms without providing enough information on the symptoms per se, then politely ask the patient to provide more details or ask clarifying questions.\n",
        "\n",
        "  prompt2 = f\"\"\" Imagine you are a professional medical doctor and speaking with a patient. \\\n",
        "  You have previously asked a question to confirm the list of symptoms that the patient has provided.\\\n",
        "  The response by the patient is in the text below, delimited by triple backticks. \\\n",
        "  ```{text}```\n",
        "  Please determine if the patient says the symptom list looks good:\n",
        "  If the patient's response indicates that the symptom list looks good, answer one word (\"proceed\") only. Do not say anything else besides the word.\n",
        "  If the patient's response indicates that the symptom list does not look good, do one of the following, whichever is the most suitable:\n",
        "      1) if the patient wants to add any symptom, then append the symptom to the original symptom list, and return the symptom list, for example: ['headache','toothache','chest pain']. Do not say anything else besides this list.\n",
        "      2) if the patient wants to revise any existing symptom in the list, then revise the list by changing the relevant symptom(s), and return the symptom list, for example, ['headache','severe toothache']. Do not say anything else besides this list.\n",
        "      3) if the patient wants to both 1 and 2, do it accordingly and return the symptom list. Do not say anything else besides this list.\n",
        "      4) if the patient only says they want to add/revise the symptoms without providing enough information on the symptoms per se, then do not respond with a list. Instead, respond to their message in conversation-style sentences, and then politely ask the patient to provide more details or ask clarifying questions.\n",
        "  \"\"\"\n",
        "\n",
        "  prompt_dict = {1: prompt1, 2: prompt2}\n",
        "  prompt = prompt_dict[prompt_id]\n",
        "  return prompt"
      ],
      "metadata": {
        "id": "GHHVcnOQW6SO"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_response(prompt, client):\n",
        "  \"\"\"\n",
        "  Returns response from prompt.\n",
        "  \"\"\"\n",
        "  response = client.chat.completions.create(\n",
        "      messages=[\n",
        "          {\n",
        "              \"role\": \"user\",\n",
        "              \"content\": prompt,\n",
        "          }\n",
        "      ],\n",
        "      model=\"gpt-3.5-turbo\",\n",
        "  )\n",
        "\n",
        "  message = response.choices[0].message.content\n",
        "\n",
        "  return message"
      ],
      "metadata": {
        "id": "0TDCSO0DW-nF"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up client\n",
        "my_api_key = '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'\n",
        "\n",
        "client = OpenAI(\n",
        "    # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
        "    api_key=my_api_key,\n",
        ")"
      ],
      "metadata": {
        "id": "97Eiz-zbXiTc"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tests for prompt 1\n",
        "# Valid test\n",
        "print(\"Testing prompt 1: valid text\\n\")\n",
        "text1 = f\"\"\"\n",
        "Patient: I woke up today with a fever, sore throat and dizziness. And a bunch of other symptoms.\n",
        "\"\"\"\n",
        "prompt = get_prompt(text=text1, prompt_id=1)\n",
        "response = get_response(prompt, client)\n",
        "print(response)\n",
        "\n",
        "# Invalid test\n",
        "print(\"\\n\\nTesting prompt 1: invalid text\\n\")\n",
        "text1_invalid = f\"\"\"\n",
        "Patient: Today's weather is good. Hahahaha. How are you?\n",
        "\"\"\"\n",
        "prompt = get_prompt(text=text1_invalid, prompt_id=1)\n",
        "response = get_response(prompt, client)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "7wXhDGCAptbH",
        "outputId": "72303b95-4dd4-4442-ceae-c6661cb80ff8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing prompt 1: valid text\n",
            "\n",
            "['fever', 'sore throat', 'dizziness']\n",
            "\n",
            "\n",
            "Testing prompt 1: invalid text\n",
            "\n",
            "I'm glad to hear that the weather is good today. As a doctor, I'm here to help with any health concerns you may have. However, I couldn't identify any symptoms from your message. Could you please provide me with any symptoms or health issues you're experiencing so that I can assist you further?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "veFn20bmsFtq"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pg4XbSM8vTA1"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}